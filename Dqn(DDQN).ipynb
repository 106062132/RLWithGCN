{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_state , 1024 )\n",
    "        self.fc2 = nn.Linear(1024 , 512)\n",
    "        self.fc3 = nn.Linear(512 , 256)\n",
    "        self.fc4 = nn.Linear(256 , 128)\n",
    "        self.fc5 = nn.Linear(128 , 64)\n",
    "        self.fc6 = nn.Linear(64 , 32)\n",
    "        self.fc7 = nn.Linear(32 , 16)\n",
    "        self.out = nn.Linear(16 , num_action )\n",
    "    \n",
    "    def forward(self , x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    '''\n",
    "    \n",
    "    This code is copied from openAI baselines\n",
    "    https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "    '''\n",
    "    def __init__(self, size):\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        \n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes , dtype = np.float32):\n",
    "        \n",
    "        \n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False,dtype=dtype))\n",
    "            actions.append(np.array(action, copy=False,dtype=np.long))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False,dtype=dtype))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t,dtype=dtype), np.array(actions , dtype = np.long), \\\n",
    "    np.array(rewards  ,dtype=dtype), np.array(obses_tp1,dtype=dtype), np.array(dones , dtype = bool)\n",
    "    \n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "    \n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.policy_network = network(num_state , num_action)\n",
    "        self.target_network = network(num_state , num_action)\n",
    "        \n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "        \n",
    "        self.steps_done = 0\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        \n",
    "        self.EPS_END = 0.05\n",
    "        self.EPS_START = 0.999\n",
    "        \n",
    "        self.EPS_DECAY = 30000\n",
    "        self.batch_size = 64\n",
    "        self.buffer = ReplayBuffer( 4000 )\n",
    "#         self.optimizer = torch.optim.Adam(self.policy_network.parameters()   , amsgrad=True)\n",
    "        self.optimizer = torch.optim.AdamW(self.policy_network.parameters(),lr=0.00002)\n",
    "    def take_action(self , x , adj_array, is_testing = False ) :\n",
    "        eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / self.EPS_DECAY)\n",
    "        if(self.steps_done%300) == 0:\n",
    "            print(eps_threshold)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        rand_val = np.random.uniform()\n",
    "        if rand_val > eps_threshold or is_testing == True:\n",
    "            val = self.policy_network(x)\n",
    "            mask_list = [0] * self.num_state\n",
    "            for item in adj_array :\n",
    "                mask_list[item] = 1\n",
    "            for i in range(len(mask_list)):\n",
    "                if(mask_list[i] == 0):\n",
    "                    val[i] = float('-Infinity')\n",
    "            action = torch.argmax(val).item()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            action = np.random.choice(adj_array)\n",
    "        \n",
    "        if is_testing == False:\n",
    "            self.steps_done += 1\n",
    "        \n",
    "        return action\n",
    "            \n",
    "    \n",
    "    def store_transition(self, state , action , reward , next_state , done ):\n",
    "        \n",
    "        self.buffer.add(state , action , reward , next_state , done)\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        \n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return \n",
    "        \n",
    "        loss_fn = torch.nn.MSELoss(reduction = 'mean')\n",
    "        \n",
    "        batch = self.buffer.sample(self.batch_size)\n",
    "        states , actions , rewards , next_states , dones = batch\n",
    "        states = torch.from_numpy(states)\n",
    "        actions = torch.from_numpy(actions).view(-1,1)\n",
    "        rewards = torch.from_numpy(rewards)\n",
    "        next_states = torch.from_numpy(next_states)\n",
    "        actions = actions.long()\n",
    "        \n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s : s != True, dones)),dtype = torch.bool)\n",
    "        non_final_next_state = next_states[non_final_mask]\n",
    "        \n",
    "        pred_q = self.policy_network(states).gather(1 , actions).view(-1) \n",
    "        next_state_value = torch.zeros(self.batch_size).detach()\n",
    "        \n",
    "        D_action = self.policy_network(non_final_next_state).argmax(1).view(-1,1)\n",
    "        next_state_value[non_final_mask] = self.target_network(non_final_next_state).gather(1 , D_action).view(-1) \n",
    "        expected_q = (next_state_value + rewards).detach()\n",
    "        \n",
    "        loss = loss_fn(pred_q , expected_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    def update_target_weight(self):\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(nodes, node1, node2):\n",
    "    x = (nodes[node1][1] - nodes[node2][1])**2\n",
    "    y = (nodes[node1][2] - nodes[node2][2])**2\n",
    "    return (x+y)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering():\n",
    "    check_list = []\n",
    "    count = -1\n",
    "    clustering_info = []\n",
    "    for index in range(num_nodes):\n",
    "        prev_check_list = []\n",
    "        if index not in check_list:\n",
    "            count+=1\n",
    "            clustering_info.append([])\n",
    "            check_list.append(index)\n",
    "            prev_check_list.append(index)\n",
    "            clustering_info[count].append(index)\n",
    "            while(len(prev_check_list)!=0):\n",
    "                next_check_list = []\n",
    "                for j in range (len(prev_check_list)):\n",
    "                    node1 = prev_check_list[j]\n",
    "                    i = 0\n",
    "                    while(i<len(nodes_dis[node1]) and nodes_dis[node1][i][1]<=t_constraint):\n",
    "                        node2 = nodes_dis[node1][i][0]\n",
    "                        if node2 not in check_list:\n",
    "                            check_list.append(node2)\n",
    "                            next_check_list.append(node2)\n",
    "                            clustering_info[count].append(node2)\n",
    "                        i+=1    \n",
    "                prev_check_list = next_check_list\n",
    "    return clustering_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communication():\n",
    "    for i in range(k_agents): \n",
    "        for j in range(i+1,k_agents):\n",
    "            if nodes_dis2[now_point[i]][now_point[j]] >= t_constraint:\n",
    "                flag[i][j] = 0\n",
    "                flag[j][i] = 0\n",
    "            elif nodes_dis2[now_point[i]][now_point[j]] < t_constraint and flag[i][j] == 0:\n",
    "                flag[i][j] = 1\n",
    "                flag[j][i] = 1\n",
    "                for k in range(num_nodes):\n",
    "                    for z in range(k+1, num_nodes):\n",
    "                        s = max(state_map[i][k][z],state_map[j][k][z])\n",
    "                        state_map[i][k][z] = s\n",
    "                        state_map[j][k][z] = s\n",
    "                        state_map[i][z][k] = s\n",
    "                        state_map[j][z][k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    data = open(\"data_10_var.txt\",'w+') \n",
    "    num_nodes = 10\n",
    "    print(num_nodes, file=data)\n",
    "    num_edges = random.randint((num_nodes-1)*(num_nodes-2)/2+1,num_nodes*(num_nodes-1)/2)\n",
    "    print(num_edges, file=data)\n",
    "    random_list = [0] * num_nodes\n",
    "    state_check = []\n",
    "    for i in range(num_nodes):\n",
    "        state_check.append([])\n",
    "        random_list[i] = i\n",
    "        pos_x = random.randint(0,1000)\n",
    "        pos_y = random.randint(0,1000)\n",
    "        print(i, pos_x, pos_y, file=data)\n",
    "    for i in range(num_edges):\n",
    "        flag_input = 0\n",
    "        while flag_input == 0: \n",
    "            sample_list = random.sample(random_list,2)\n",
    "            length = random.randint(0,1000)\n",
    "            a = sample_list[0]\n",
    "            b = sample_list[1]\n",
    "            if b not in state_check[a]:\n",
    "                state_check[a].append(b)\n",
    "                state_check[b].append(a)\n",
    "                print(a, b, length, file=data)\n",
    "                flag_input = 1\n",
    "            else:\n",
    "                flag_input = 0\n",
    "    k_agents = 3\n",
    "    print(k_agents, file=data)\n",
    "    for i in range(k_agents):\n",
    "        now_point = random.randint(0,num_nodes-1)\n",
    "        speed = random.randint(1,10)\n",
    "        print(i, now_point, speed, file=data)\n",
    "    constraint = 500\n",
    "    print(constraint, file=data)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f8dccdd3cf4383a1b0f3b1683c6f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[20, 5, 21]\n",
      "0.999\n",
      "0.9895572922279605\n",
      "0.9802085409681107\n",
      "0.9709528113375342\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-cf636ba796de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnow_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_step\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_step\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_step\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-be1d4f9f6856>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_q\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mexpected_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = open('data_50.txt')\n",
    "lines = file.readlines()\n",
    "num_nodes = int(lines[0])\n",
    "num_edges = int(lines[1])\n",
    "agent = Agent(50 , 50)\n",
    "reward_history = []\n",
    "cost = 3000\n",
    "for e in tqdm(range(50)):\n",
    "    #generator()\n",
    "#     file = open('data.txt')\n",
    "#     lines = file.readlines()\n",
    "#     num_nodes = int(lines[0])\n",
    "#     num_edges = int(lines[1])\n",
    "    print(cost)\n",
    "#     if(cost <= 1843):\n",
    "#         break\n",
    "    nodes = []\n",
    "    state = []\n",
    "    edge_len = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    god_map = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    flag = [[0]*k_agents for i in range(k_agents)]\n",
    "    nodes_dis = []\n",
    "    nodes_dis2 = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    on_nodes = []\n",
    "    info_speed = []\n",
    "    features = []\n",
    "    prev_features = []\n",
    "    Adj = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        state.append([])\n",
    "        nodes_dis.append([])\n",
    "        on_nodes.append([])\n",
    "        curLine = lines[i+2].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        nodes.append([intLine[0], intLine[1], intLine[2]])\n",
    "        for j in range(i-1, -1, -1):\n",
    "            dis = distance(nodes, i, j)\n",
    "            nodes_dis[i].append((j, dis))\n",
    "            nodes_dis[j].append((i, dis))\n",
    "            nodes_dis2[i][j] = dis\n",
    "            nodes_dis2[j][i] = dis\n",
    "    for i in range(len(nodes_dis)):\n",
    "        nodes_dis[i].sort(key=lambda nodes_dis: nodes_dis[1])\n",
    "\n",
    "    for i in range(num_edges):\n",
    "        curLine = lines[i+2+num_nodes].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        state[intLine[0]].append(intLine[1])\n",
    "        state[intLine[1]].append(intLine[0])\n",
    "        edge_len[intLine[0]][intLine[1]] = intLine[2]\n",
    "        edge_len[intLine[1]][intLine[0]] = intLine[2]\n",
    "        Adj[intLine[0]][intLine[1]] = 1\n",
    "        Adj[intLine[1]][intLine[0]] = 1\n",
    "    Adj = torch.FloatTensor(Adj)\n",
    "    k_agents = int(lines[2+num_nodes+num_edges])\n",
    "    \n",
    "    for k in range(k_agents):\n",
    "        features.append([])\n",
    "        prev_features.append([])\n",
    "        for i in range(num_nodes):\n",
    "            features[k].append([])\n",
    "            prev_features[k].append([])\n",
    "            for j in range(num_nodes):\n",
    "                features[k][i].append(0)\n",
    "                prev_features[k][i].append(0)\n",
    "        \n",
    "    now_point = [0] * k_agents\n",
    "    speed = [0]*k_agents\n",
    "    target = [0]*k_agents\n",
    "    location = [0]*k_agents\n",
    "    x_agent = []\n",
    "    y_agent = []\n",
    "\n",
    "    for i in range(k_agents):\n",
    "        x_agent.append([])\n",
    "        y_agent.append([])\n",
    "        info_speed.append([])\n",
    "        curLine = lines[i+3+num_nodes+num_edges].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        now_point[intLine[0]] = intLine[1]\n",
    "        #now_point[i] = random.randint(0, num_nodes-1)\n",
    "        speed[intLine[0]] = intLine[2]\n",
    "\n",
    "    t_constraint = int(lines[3+num_nodes+num_edges+k_agents])\n",
    "       \n",
    "    print(now_point)\n",
    "#     print(state)\n",
    "#     print(speed)\n",
    "#     print(edge_len)\n",
    "    \n",
    "    history_route = []\n",
    "    state_map = []\n",
    "    for i in range(k_agents):\n",
    "        history_route.append([])\n",
    "        history_route[i].append(now_point[i])\n",
    "        on_nodes[now_point[i]].append(i)\n",
    "        state_map.append([]) \n",
    "    for i in range(k_agents):\n",
    "        state_map[i] = [[0] * num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    finish_count = 0\n",
    "    cost = 0\n",
    "    pre_step = [0]*k_agents\n",
    "    info_clustering = clustering()\n",
    "    reward_sum = 0.0\n",
    "    while finish_count < num_edges:\n",
    "        communication()\n",
    "#         for i in range(k_agents):\n",
    "#             for state_index in range(num_nodes):\n",
    "#                 for state_index2 in range(num_nodes):\n",
    "#                     if(state_map[i][state_index][state_index2] >= 1):\n",
    "#                         features[i][state_index][state_index2] = 1\n",
    "        cost+=1\n",
    "        for i in range(k_agents):\n",
    "            list_x = []\n",
    "            list_y = []\n",
    "            if target[i]==0:\n",
    "                  \n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(state_map[i][state_index][state_index2] >= 1):\n",
    "                            features[i][state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features[i][now_point[i]]),state[pre_step[i]])\n",
    "                for index_i in range(len(features[i])):\n",
    "                    for index_j in range(len(features[i][index_i])):\n",
    "                        prev_features[i][index_i][index_j] = features[i][index_i][index_j]\n",
    "                now_point[i] = action\n",
    "                if(state_map[i][now_point[i]][pre_step[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[i][now_point[i]][pre_step[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 100000):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "                state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                \n",
    "                features[i][pre_step[i]][now_point[i]] = 1\n",
    "                features[i][now_point[i]][pre_step[i]] = 1\n",
    "                agent.store_transition(np.array(prev_features[i][pre_step[i]]) , action , reward , np.array(features[i][pre_step[i]]), done)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "            location[i]+=1\n",
    "            draw_flag = 0\n",
    "            while location[i]>=target[i]:\n",
    "#                 state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "#                 state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                history_route[i].append(now_point[i])\n",
    "#                 if god_map[now_point[i]][pre_step[i]]==0:\n",
    "#                     finish_count+=1\n",
    "#                 god_map[now_point[i]][pre_step[i]] += 1\n",
    "#                 god_map[pre_step[i]][now_point[i]] += 1\n",
    "\n",
    "                if(draw_flag == 0):\n",
    "                    pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                    pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "                else:\n",
    "                    pre_x = nodes[pre_step[i]][1]\n",
    "                    pre_y = nodes[pre_step[i]][2] \n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "\n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(state_map[i][state_index][state_index2] >= 1):\n",
    "                            features[i][state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features[i][now_point[i]]),state[pre_step[i]])\n",
    "                for index_i in range(len(features[i])):\n",
    "                    for index_j in range(len(features[i][index_i])):\n",
    "                        prev_features[i][index_i][index_j] = features[i][index_i][index_j]\n",
    "                now_point[i] = action\n",
    "                if(state_map[i][now_point[i]][pre_step[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[i][now_point[i]][pre_step[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 100000):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "                state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                \n",
    "                features[i][pre_step[i]][now_point[i]] = 1\n",
    "                features[i][now_point[i]][pre_step[i]] = 1\n",
    "                agent.store_transition(np.array(prev_features[i][pre_step[i]]) , action , reward , np.array(features[i][pre_step[i]]), done)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                location[i] = location[i]-target[i]\n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "                if i in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].remove(i)\n",
    "                draw_flag = 1\n",
    "            if (draw_flag == 1):\n",
    "                pre_x = nodes[pre_step[i]][1] \n",
    "                pre_y = nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                list_x.append([pre_x, now_x])\n",
    "                list_y.append([pre_y, now_y])\n",
    "                x_agent[i].append(list_x)\n",
    "                y_agent[i].append(list_y)\n",
    "            else:\n",
    "                pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                x_agent[i].append([pre_x, now_x])\n",
    "                y_agent[i].append([pre_y, now_y])\n",
    "\n",
    "            if (location[i]/target[i]) > 0.5:\n",
    "                if i not in on_nodes[now_point[i]]:\n",
    "                    on_nodes[now_point[i]].append(i)\n",
    "            else:\n",
    "                if i not in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].append(i)\n",
    "    reward_history.append(reward_sum)\n",
    "    if e  % 1 == 0:\n",
    "        print(reward_sum)\n",
    "    if e > 0 and e % 10 == 0:\n",
    "        agent.update_target_weight()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f682c060470>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc7c47c668b4f138d1b33a56dc2d64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[7, 3, 5]\n",
      "56.114000000000004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file=open('data.txt')\n",
    "lines = file.readlines()\n",
    "#num_nodes = int(lines[0])\n",
    "#num_edges = int(lines[1])\n",
    "#agent = Agent(num_nodes , num_nodes)\n",
    "#reward_history = []\n",
    "cost = 3000\n",
    "for e in tqdm(range(1)):\n",
    "    print(cost)\n",
    "#     if(cost <= 1843):\n",
    "#         break\n",
    "    nodes = []\n",
    "    state = []\n",
    "    edge_len = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    god_map = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    nodes_dis = []\n",
    "    nodes_dis2 = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    on_nodes = []\n",
    "    info_speed = []\n",
    "    features = []\n",
    "    prev_features = []\n",
    "    Adj = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        state.append([])\n",
    "        nodes_dis.append([])\n",
    "        on_nodes.append([])\n",
    "        curLine = lines[i+2].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        nodes.append([intLine[0], intLine[1], intLine[2]])\n",
    "        for j in range(i-1, -1, -1):\n",
    "            dis = distance(nodes, i, j)\n",
    "            nodes_dis[i].append((j, dis))\n",
    "            nodes_dis[j].append((i, dis))\n",
    "            nodes_dis2[i][j] = dis\n",
    "            nodes_dis2[j][i] = dis\n",
    "    for i in range(len(nodes_dis)):\n",
    "        nodes_dis[i].sort(key=lambda nodes_dis: nodes_dis[1])\n",
    "\n",
    "    for i in range(num_edges):\n",
    "        curLine = lines[i+2+num_nodes].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        state[intLine[0]].append(intLine[1])\n",
    "        state[intLine[1]].append(intLine[0])\n",
    "        edge_len[intLine[0]][intLine[1]] = intLine[2]\n",
    "        edge_len[intLine[1]][intLine[0]] = intLine[2]\n",
    "        Adj[intLine[0]][intLine[1]] = 1\n",
    "        Adj[intLine[1]][intLine[0]] = 1\n",
    "    Adj = torch.FloatTensor(Adj)\n",
    "    k_agents = int(lines[2+num_nodes+num_edges])\n",
    "    \n",
    "    for k in range(k_agents):\n",
    "        features.append([])\n",
    "        prev_features.append([])\n",
    "        for i in range(num_nodes):\n",
    "            features[k].append([])\n",
    "            prev_features[k].append([])\n",
    "            for j in range(num_nodes):\n",
    "                features[k][i].append(0)\n",
    "                prev_features[k][i].append(0)\n",
    "        \n",
    "    now_point = [0] * k_agents\n",
    "    speed = [0]*k_agents\n",
    "    target = [0]*k_agents\n",
    "    location = [0]*k_agents\n",
    "    x_agent = []\n",
    "    y_agent = []\n",
    "\n",
    "    for i in range(k_agents):\n",
    "        x_agent.append([])\n",
    "        y_agent.append([])\n",
    "        info_speed.append([])\n",
    "        curLine = lines[i+3+num_nodes+num_edges].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        now_point[intLine[0]] = intLine[1]\n",
    "        #now_point[i] = random.randint(0, num_nodes-1)\n",
    "        speed[intLine[0]] = intLine[2]\n",
    "\n",
    "    t_constraint = int(lines[3+num_nodes+num_edges+k_agents])\n",
    "       \n",
    "    print(now_point)\n",
    "#     print(state)\n",
    "#     print(speed)\n",
    "#     print(edge_len)\n",
    "    \n",
    "    history_route = []\n",
    "    state_map = []\n",
    "    for i in range(k_agents):\n",
    "        history_route.append([])\n",
    "        history_route[i].append(now_point[i])\n",
    "        on_nodes[now_point[i]].append(i)\n",
    "        state_map.append([]) \n",
    "    for i in range(k_agents):\n",
    "        state_map[i] = [[0] * num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    finish_count = 0\n",
    "    cost = 0\n",
    "    pre_step = [0]*k_agents\n",
    "    info_clustering = clustering()\n",
    "    reward_sum = 0.0\n",
    "    while finish_count < num_edges:\n",
    "        communication()\n",
    "#         for i in range(k_agents):\n",
    "#             for state_index in range(num_nodes):\n",
    "#                 for state_index2 in range(num_nodes):\n",
    "#                     if(state_map[i][state_index][state_index2] >= 1):\n",
    "#                         features[i][state_index][state_index2] = 1\n",
    "        cost+=1\n",
    "        for i in range(k_agents):\n",
    "            list_x = []\n",
    "            list_y = []\n",
    "            if target[i]==0:\n",
    "                  \n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(state_map[i][state_index][state_index2] >= 1):\n",
    "                            features[i][state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = model2.take_action(np.array(features[i][now_point[i]]),state[pre_step[i]],True)\n",
    "                for index_i in range(len(features[i])):\n",
    "                    for index_j in range(len(features[i][index_i])):\n",
    "                        prev_features[i][index_i][index_j] = features[i][index_i][index_j]\n",
    "                now_point[i] = action\n",
    "                if(god_map[now_point[i]][pre_step[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[i][now_point[i]][pre_step[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 3000):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "                state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                \n",
    "                features[i][pre_step[i]][now_point[i]] = 1\n",
    "                features[i][now_point[i]][pre_step[i]] = 1\n",
    "#                 agent.store_transition(np.array(prev_features[i][pre_step[i]]) , action , reward , np.array(features[i][pre_step[i]]), done)\n",
    "#                 agent.update_parameters()\n",
    "                \n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "            location[i]+=1\n",
    "            draw_flag = 0\n",
    "            while location[i]>=target[i]:\n",
    "#                 state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "#                 state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                history_route[i].append(now_point[i])\n",
    "#                 if god_map[now_point[i]][pre_step[i]]==0:\n",
    "#                     finish_count+=1\n",
    "#                 god_map[now_point[i]][pre_step[i]] += 1\n",
    "#                 god_map[pre_step[i]][now_point[i]] += 1\n",
    "\n",
    "                if(draw_flag == 0):\n",
    "                    pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                    pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "                else:\n",
    "                    pre_x = nodes[pre_step[i]][1]\n",
    "                    pre_y = nodes[pre_step[i]][2] \n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "\n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(state_map[i][state_index][state_index2] >= 1):\n",
    "                            features[i][state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = model2.take_action(np.array(features[i][now_point[i]]),state[pre_step[i]],True)\n",
    "                for index_i in range(len(features[i])):\n",
    "                    for index_j in range(len(features[i][index_i])):\n",
    "                        prev_features[i][index_i][index_j] = features[i][index_i][index_j]\n",
    "                now_point[i] = action\n",
    "                if(god_map[now_point[i]][pre_step[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[i][now_point[i]][pre_step[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 3000):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "                state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                \n",
    "                features[i][pre_step[i]][now_point[i]] = 1\n",
    "                features[i][now_point[i]][pre_step[i]] = 1\n",
    "#                 agent.store_transition(np.array(prev_features[i][pre_step[i]]) , action , reward , np.array(features[i][pre_step[i]]), done)\n",
    "#                 agent.update_parameters()\n",
    "                \n",
    "                location[i] = location[i]-target[i]\n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "                if i in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].remove(i)\n",
    "                draw_flag = 1\n",
    "            if (draw_flag == 1):\n",
    "                pre_x = nodes[pre_step[i]][1] \n",
    "                pre_y = nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                list_x.append([pre_x, now_x])\n",
    "                list_y.append([pre_y, now_y])\n",
    "                x_agent[i].append(list_x)\n",
    "                y_agent[i].append(list_y)\n",
    "            else:\n",
    "                pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                x_agent[i].append([pre_x, now_x])\n",
    "                y_agent[i].append([pre_y, now_y])\n",
    "\n",
    "            if (location[i]/target[i]) > 0.5:\n",
    "                if i not in on_nodes[now_point[i]]:\n",
    "                    on_nodes[now_point[i]].append(i)\n",
    "            else:\n",
    "                if i not in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].append(i)\n",
    "    reward_history.append(reward_sum)\n",
    "    if e  % 1 == 0:\n",
    "        print(reward_sum)\n",
    "    if e > 0 and e % 30 == 0:\n",
    "        agent.update_target_weight()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  1469 ticks\n"
     ]
    }
   ],
   "source": [
    "print('cost: ', cost, 'ticks')\n",
    "#print(history_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent, f\"DQN_10_nogodmap_v2.ptmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load('DQN_10_nogodmap_v2.ptmodel',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; trying to use html instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5813ec1c4db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0manimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFuncAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manimation_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'basic_animation3.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 writer = alt_writer(\n\u001b[1;32m   1110\u001b[0m                     \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbitrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                     extra_args=extra_args, metadata=metadata)\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Animation.save using %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "x = []\n",
    "y = []\n",
    "for i in range(num_nodes):\n",
    "    node1 = i\n",
    "    for node2 in state[i]:\n",
    "        x.append([nodes[node1][1], nodes[node2][1]])\n",
    "        y.append([nodes[node1][2], nodes[node2][2]])\n",
    "\n",
    "x_1data = []\n",
    "y_1data = []\n",
    "x_2data = []\n",
    "y_2data = []\n",
    "x_3data = []\n",
    "y_3data = []\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_ylim(0, 1000)\n",
    "line, = ax.plot(0, 0, color = 'silver')\n",
    "line_1, = ax.plot(0, 0, color='red')\n",
    "line_2, = ax.plot(0, 0, color='black')\n",
    "line_3, = ax.plot(0, 0, color='blue')\n",
    "ball_1 = plt.Circle((5, -5), 18, fc='red')\n",
    "ball_2 = plt.Circle((5, -5), 18, fc='black')\n",
    "ball_3 = plt.Circle((5, -5), 18, fc='blue')\n",
    "def animation_frame(i):\n",
    "    \n",
    "    if i >= 0:\n",
    "        if(i<len(x_agent[0])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[0][i])):\n",
    "                if isinstance(x_agent[0][i][j], list):\n",
    "                    x_1data.append(x_agent[0][i][j])\n",
    "                    y_1data.append(y_agent[0][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_1.center = (x_agent[0][i][j][1], y_agent[0][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_1data.append(x_agent[0][i])\n",
    "                y_1data.append(y_agent[0][i])\n",
    "                ball_1.center = (x_agent[0][i][1], y_agent[0][i][1])\n",
    "\n",
    "            line_1.set_xdata(x_1data)\n",
    "            line_1.set_ydata(y_1data)\n",
    "            \n",
    "            \n",
    "\n",
    "        if(i<len(x_agent[1])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[1][i])):\n",
    "                if isinstance(x_agent[1][i][j], list):\n",
    "                    x_2data.append(x_agent[1][i][j])\n",
    "                    y_2data.append(y_agent[1][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_2.center = (x_agent[1][i][j][1], y_agent[1][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_2data.append(x_agent[1][i])\n",
    "                y_2data.append(y_agent[1][i])\n",
    "                ball_2.center = (x_agent[1][i][1], y_agent[1][i][1])\n",
    "                \n",
    "            line_2.set_xdata(x_2data)\n",
    "            line_2.set_ydata(y_2data)\n",
    "            \n",
    "        if(i<len(x_agent[2])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[2][i])):\n",
    "                if isinstance(x_agent[2][i][j], list):\n",
    "                    x_3data.append(x_agent[2][i][j])\n",
    "                    y_3data.append(y_agent[2][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_3.center = (x_agent[2][i][j][1], y_agent[2][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_3data.append(x_agent[2][i])\n",
    "                y_3data.append(y_agent[2][i])\n",
    "                ball_3.center = (x_agent[2][i][1], y_agent[2][i][1])\n",
    "\n",
    "            line_3.set_xdata(x_3data)\n",
    "            line_3.set_ydata(y_3data)\n",
    "    \n",
    "    return line_1,line_2,line_3,ball_1,ball_2,ball_3,\n",
    "def init():\n",
    "    line.set_xdata(x)\n",
    "    line.set_ydata(y)\n",
    "    \n",
    "    line_1.set_xdata(x_agent[0][0][0])\n",
    "    line_1.set_ydata(y_agent[0][0][0])\n",
    "    \n",
    "    line_2.set_xdata(x_agent[1][0][0])\n",
    "    line_2.set_ydata(y_agent[1][0][0])\n",
    "    \n",
    "    line_3.set_xdata(x_agent[2][0][0])\n",
    "    line_3.set_ydata(y_agent[2][0][0])\n",
    "    \n",
    "    ball_1.center = (x_agent[0][0][0], y_agent[0][0][0])\n",
    "    ax.add_patch(ball_1)\n",
    "    \n",
    "    ball_2.center = (x_agent[1][0][0], y_agent[1][0][0])\n",
    "    ax.add_patch(ball_2)\n",
    "    \n",
    "    ball_3.center = (x_agent[2][0][0], y_agent[2][0][0])\n",
    "    ax.add_patch(ball_3)\n",
    "    \n",
    "    return line, line_1,line_2,line_3, ball_1,ball_2,ball_3,\n",
    "    \n",
    "animation = FuncAnimation(fig, func=animation_frame, frames=np.arange(-2, len(x_agent[0]), 1), init_func=init, interval=10)\n",
    "plt.show()\n",
    "animation.save('basic_animation3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 398 396\n"
     ]
    }
   ],
   "source": [
    "print(len(x_1data),len(x_2data),len(x_3data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 3, 1], [3, 0, 2, 4], [3, 4, 1], [0, 1, 2, 4], [0, 2, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
